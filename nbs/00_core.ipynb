{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core functionality\n",
    "\n",
    "> Core functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import transformers\n",
    "import PIL.Image\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from dataclasses import asdict\n",
    "from collections import OrderedDict\n",
    "from typing import Union, Tuple, Sequence, Set\n",
    "from numpy.random import RandomState\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torchvision.transforms import (CenterCrop, \n",
    "                                    RandomErasing,\n",
    "                                    RandomAutocontrast,\n",
    "                                    Compose, \n",
    "                                    Normalize, \n",
    "                                    RandomHorizontalFlip,\n",
    "                                    RandomResizedCrop, \n",
    "                                    Resize, \n",
    "                                    RandomAdjustSharpness,\n",
    "                                    ToTensor)\n",
    "import torch\n",
    "from transformers import AutoFeatureExtractor, TrainingArguments, Trainer\n",
    "from transformers import AutoModelForImageClassification\n",
    "from evaluate import load as load_metric\n",
    "from rich import print\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "from tqdm.auto import tqdm\n",
    "from imagededup.methods import PHash\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Git hooks.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git lfs update --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "from toolz.dicttoolz import valmap\n",
    "from collections import Counter\n",
    "from toolz import frequencies\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://huggingface.co/datasets/davanstrien/testgitupload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset = Path(\"testdataset\")\n",
    "testdataset.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = {\"control\": Image.open(\"testdata/add_ms_05422_fcontrol1.jpg\"),\n",
    "\"flysheet\": Image.open(\"testdata/add_ms_9403_fse001v.jpg\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in {\"control\",\"flysheet\"}:\n",
    "    folder = testdataset/label\n",
    "    folder.mkdir()\n",
    "    image = test_images[label]\n",
    "    for i in range(100):\n",
    "        fname = f\"{i}_{label}\"\n",
    "        image.save(f\"{folder}/{fname}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phasher = PHash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 15:11:40,919: INFO Start: Calculating hashes...\n",
      "0it [00:00, ?it/s]\n",
      "2022-12-11 15:11:41,012: INFO End: Calculating hashes!\n"
     ]
    }
   ],
   "source": [
    "encodings = phasher.encode_images(image_dir='testdataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 15:11:41,028: INFO Start: Calculating hashes...\n",
      "0it [00:00, ?it/s]\n",
      "2022-12-11 15:11:41,102: INFO End: Calculating hashes!\n",
      "2022-12-11 15:11:41,104: INFO Start: Evaluating hamming distances for getting duplicates\n",
      "2022-12-11 15:11:41,107: INFO Start: Retrieving duplicates using Cython Brute force algorithm\n",
      "0it [00:00, ?it/s]\n",
      "2022-12-11 15:11:41,200: INFO End: Retrieving duplicates using Cython Brute force algorithm\n",
      "2022-12-11 15:11:41,202: INFO End: Evaluating hamming distances for getting duplicates\n"
     ]
    }
   ],
   "source": [
    "duplicates = phasher.find_duplicates(image_dir=\"testdataset\", encoding_map=encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{}"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2daab5aaed44fcb84c3abcc74a9ed7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Resolving data files:   0%|          | 0/200 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-162fd80ee2ca094f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /Users/dvanstrien/.cache/huggingface/datasets/imagefolder/default-162fd80ee2ca094f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n",
      "                "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0699d51f520477eaea442530e8c74fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #6:   0%|          | 0/13 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e21b5d6f2145c4913a0ad5dac2c5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #10:   0%|          | 0/12 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1905bd6ccf5b4c16a3eefd048ba6d69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #15:   0%|          | 0/12 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3106955e752c4755947f966dc3fbe611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #5:   0%|          | 0/13 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d182bfc4dc194c1591f6c672a863a1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #7:   0%|          | 0/13 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1858f1ea38994c839f9b237662800c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #2:   0%|          | 0/13 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68f3b722d7242528925f70b6afc4dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #12:   0%|          | 0/12 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f3a942ee4d4176822654b5d7fa569e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #0:   0%|          | 0/13 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6004468ee6434bf58fff4d4570b100a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #3:   0%|          | 0/13 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971efcfa57b1489397c83d46408fea29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #4:   0%|          | 0/13 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcb8d83b4c647f58e6b4c99811fabcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #1:   0%|          | 0/13 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7118c97d83ce4916903643a095fba049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #8:   0%|          | 0/12 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7968131cdf465ca932a248197e9ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #9:   0%|          | 0/12 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8426924c874c08b0592bdbde089209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #11:   0%|          | 0/12 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104d033933414515bd6b082ac6712f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #14:   0%|          | 0/12 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cff6fee5414098860e7d5b412c729d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files #13:   0%|          | 0/12 [00:00<?, ?obj/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0088d08025a44b60be50bdb8926b78fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Downloading data files: 0it [00:00, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa770abf543247a2802c41c2c7202e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Extracting data files: 0it [00:00, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afebbcaf8d449568f73229e4e6921c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /Users/dvanstrien/.cache/huggingface/datasets/imagefolder/default-162fd80ee2ca094f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"imagefolder\",data_dir=\"testdataset\",\n",
    "                  streaming=False,\n",
    "                  split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['image', 'label'],\n    num_rows: 200\n})"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'/Users/dvanstrien/Documents/DS/gym/nbs/testdataset/control/0_control.jpg'"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['image'].filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def filter_bad_images(ds: Dataset):\n",
    "    idx = list(range(len(ds)))\n",
    "    for i in tqdm(idx):\n",
    "        try:\n",
    "            if isinstance(ds[i]['image'], Image.Image):\n",
    "                continue\n",
    "            else:\n",
    "                idx.pop(i)\n",
    "        except OSError:\n",
    "            idx.pop(i)\n",
    "    return ds.select(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4e400686434ab5af356d50cb013a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = filter_bad_images(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['image', 'label'],\n    num_rows: 200\n})"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_fpath(ds: Dataset):\n",
    "   return ds.map(lambda x: {'fpath': x['image'].filename})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e05981dbd2e491990f34d3880200193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/200 [00:00<?, ?ex/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = get_fpath(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=687x1000>,\n 'label': 0,\n 'fpath': '/Users/dvanstrien/Documents/DS/gym/nbs/testdataset/control/0_control.jpg'}"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =  '/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r (1).jpg.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r (1).jpg.jpg'"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = re.sub(r\"(\\(\\d\\))\",\"\",f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r '"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def return_base_path_deduplicated(x):\n",
    "    f = x['fpath']\n",
    "    f = re.sub(r\"(\\(\\d\\))\",\"\",f)\n",
    "    f = f.split(\".\")[0]\n",
    "    f = f.rstrip()\n",
    "    return {\"clean_path\": re.sub(r\"(\\(\\d\\))\",\"\",f)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_uniques(example, uniques, column='clean_path'):\n",
    "    if example[column] in uniques:\n",
    "        uniques.remove(example[column])\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def drop_duplicates(ds):\n",
    "    ds = ds.map(return_base_path_deduplicated)\n",
    "    uniques = set(ds['clean_path'])\n",
    "    ds = ds.filter(check_uniques, fn_kwargs={\"uniques\":uniques})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd6ad49bea74d4d8d96944e10ce24cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/200 [00:00<?, ?ex/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00096f29d6784934bbd61eab6d52eaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = drop_duplicates(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['image', 'label', 'fpath', 'clean_path'],\n    num_rows: 200\n})"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_id(example):\n",
    "    x = example[\"fpath\"]\n",
    "    x = Path(x).name.split(\"_\")\n",
    "    return {\"id\": \"_\".join(x[:2] if len(x) >= 3 else x[:3])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, valid, test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_w_stratify(\n",
    "    ds,\n",
    "    test_size: Union[int, float],\n",
    "    random_state: Union[int, RandomState, None] = None,\n",
    ") -> Tuple[Dataset, Dataset]:\n",
    "    labels = ds['label']\n",
    "    label_array = np.array(labels)\n",
    "    train_inds, valid_inds = next(\n",
    "        StratifiedShuffleSplit(\n",
    "            n_splits=3, test_size=test_size, random_state=random_state\n",
    "        ).split(np.zeros(len(labels)), y=label_array)\n",
    "    )\n",
    "    return ds.select(train_inds), ds.select(valid_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = split_w_stratify(ds, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_allclose(train.shape, valid.shape,rtol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 50, 1: 50}"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_freqs = frequencies(train['label'])\n",
    "train_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "odict_values([25.0, 25.0])"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_percentages =  OrderedDict(sorted(valmap(lambda x: x/len(train_freqs),train_freqs).items())).values()\n",
    "train_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "odict_values([25.0, 25.0])"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_freqs = frequencies(valid['label'])\n",
    "valid_percentages = OrderedDict(sorted(valmap(lambda x: x/len(valid_freqs),valid_freqs).items())).values()\n",
    "valid_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_allclose(list(train_percentages), list(valid_percentages), atol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_valid_split_w_stratify(\n",
    "    ds,\n",
    "    valid_size: Union[int,float]=None,\n",
    "    test_size: Union[int, float]=0.2,\n",
    "    train_size: Union[int, float, None] = None,\n",
    "    random_state: Union[int, RandomState, None] = None,\n",
    ") -> Tuple[Dataset,Dataset, Dataset]:\n",
    "    train, valid_test = split_w_stratify(ds, test_size=test_size)\n",
    "    valid, test = split_w_stratify(valid_test, test_size=0.1)\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = train_valid_split_w_stratify(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prepare_dataset(ds):\n",
    "    print(\"Preparing dataset...\")\n",
    "    print(\"dropping duplicates...\")\n",
    "    ds = filter_bad_images(ds)\n",
    "    # ds = get_fpath(ds)\n",
    "    # ds = drop_duplicates(ds)\n",
    "    # print(\"getting ID...\")\n",
    "    # ds = ds.map(get_id)\n",
    "    print(\"creating train, valid, test splits...\")\n",
    "    train, valid, test = train_valid_split_w_stratify(ds)\n",
    "    data = {\"train\": train,\n",
    "            \"valid\": valid,\n",
    "            \"test\": test}\n",
    "    for k,v  in data.items():\n",
    "        print(f\"{k} has {len(v)} examples\")\n",
    "    return train,valid,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e9078625e04940a5957db2b21f7aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Resolving data files:   0%|          | 0/200 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-162fd80ee2ca094f\n",
      "Found cached dataset imagefolder (/Users/dvanstrien/.cache/huggingface/datasets/imagefolder/default-162fd80ee2ca094f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"imagefolder\",data_dir=\"testdataset\",\n",
    "                  split='train',use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n",
      "text/plain": "Preparing dataset\u001b[33m...\u001b[0m\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">dropping duplicates<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n",
      "text/plain": "dropping duplicates\u001b[33m...\u001b[0m\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba708e5db54344768b073e056495b9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">creating train, valid, test splits<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n",
      "text/plain": "creating train, valid, test splits\u001b[33m...\u001b[0m\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">train has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span> examples\n</pre>\n",
      "text/plain": "train has \u001b[1;36m160\u001b[0m examples\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">valid has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> examples\n</pre>\n",
      "text/plain": "valid has \u001b[1;36m36\u001b[0m examples\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> examples\n</pre>\n",
      "text/plain": "test has \u001b[1;36m4\u001b[0m examples\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(Dataset({\n     features: ['image', 'label'],\n     num_rows: 160\n }),\n Dataset({\n     features: ['image', 'label'],\n     num_rows: 36\n }),\n Dataset({\n     features: ['image', 'label'],\n     num_rows: 4\n }))"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,valid,test = prepare_dataset(ds)\n",
    "train,valid,test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"davanstrien/vit-base-patch16-224-in21k-base-manuscripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "224"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)\n",
    "feature_extractor.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prepare_transforms(model_checkpoint, train_ds, valid_ds, test_ds=None):\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)\n",
    "    normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "    _train_transforms = Compose(\n",
    "            [\n",
    "                Resize((feature_extractor.size['height'],feature_extractor.size['width'])),\n",
    "                RandomAdjustSharpness(0.1),\n",
    "                RandomAutocontrast(),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "                RandomErasing()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    _val_transforms = Compose(\n",
    "            [\n",
    "                Resize((feature_extractor.size['height'],feature_extractor.size['width'])),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def train_transforms(examples):\n",
    "        examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "        return examples\n",
    "\n",
    "    def val_transforms(examples):\n",
    "        examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "        return examples\n",
    "    if test_ds is not None:\n",
    "        test_ds.set_transform(val_transforms)\n",
    "    train_ds.set_transform(train_transforms)\n",
    "    valid_ds.set_transform(val_transforms)\n",
    "    return train_ds, valid_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds, test_ds = prepare_transforms(model_checkpoint, train,valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class FlyswotData:\n",
    "    train_ds: datasets.arrow_dataset.Dataset\n",
    "    valid_ds: datasets.arrow_dataset.Dataset\n",
    "    test_ds: datasets.arrow_dataset.Dataset\n",
    "    id2label: Dict[int,str]\n",
    "    label2id: Dict[str,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prep_data(ds, model_checkpoint=None):\n",
    "    try:\n",
    "        labels = ds.info.features['label'].names\n",
    "        id2label = dict(enumerate(labels))\n",
    "        label2id = {v:k for k,v in id2label.items()}\n",
    "        train, valid, test = prepare_dataset(ds)\n",
    "        train_ds, valid_ds, test_ds = prepare_transforms(model_checkpoint, train, valid, test)\n",
    "        return FlyswotData(train_ds, valid_ds, test_ds, id2label, label2id)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"{e} make sure you are logged into the Hugging Face Hub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n",
      "text/plain": "Preparing dataset\u001b[33m...\u001b[0m\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">dropping duplicates<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n",
      "text/plain": "dropping duplicates\u001b[33m...\u001b[0m\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e62eb6c082a4f18bee1282de6c636f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">creating train, valid, test splits<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n",
      "text/plain": "creating train, valid, test splits\u001b[33m...\u001b[0m\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">train has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span> examples\n</pre>\n",
      "text/plain": "train has \u001b[1;36m160\u001b[0m examples\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">valid has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> examples\n</pre>\n",
      "text/plain": "valid has \u001b[1;36m36\u001b[0m examples\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> examples\n</pre>\n",
      "text/plain": "test has \u001b[1;36m4\u001b[0m examples\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "FlyswotData(train_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 160\n}), valid_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 36\n}), test_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 4\n}), id2label={0: 'control', 1: 'flysheet'}, label2id={'control': 0, 'flysheet': 1})"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prep_data(ds, model_checkpoint=model_checkpoint)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "FlyswotData(train_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 160\n}), valid_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 36\n}), test_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 4\n}), id2label={0: 'control', 1: 'flysheet'}, label2id={'control': 0, 'flysheet': 1})"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds, test_ds, id2label, label2id = asdict(data).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['image', 'label'],\n    num_rows: 160\n})"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_model(data, \n",
    "                model_checkpoint,\n",
    "                num_epochs=50,\n",
    "                hub_model_id=\"flyswot\",\n",
    "                tune=False,\n",
    "               fp16=True):\n",
    "    transformers.logging.set_verbosity_warning()\n",
    "    train_ds, valid_ds, test_ds, id2label, label2id = asdict(data).values()\n",
    "    print(train_ds)\n",
    "    model = AutoModelForImageClassification.from_pretrained(model_checkpoint, num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                  label2id=label2id, ignore_mismatched_sizes=True)\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)\n",
    "    args = TrainingArguments(\n",
    "    \"output_dir\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    hub_model_id=f\"flyswot/{hub_model_id}\",\n",
    "    overwrite_output_dir=True,\n",
    "    push_to_hub=True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4, \n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.1,disable_tqdm=False,\n",
    "    fp16=fp16,\n",
    "   # load_best_model_at_end=True,\n",
    "    #metric_for_best_model=\"f1\",\n",
    "    logging_dir='logs',\n",
    "    remove_unused_columns=False,\n",
    "    save_total_limit=10,\n",
    "    optim=\"adamw_torch\",\n",
    "    seed=42,    \n",
    ")\n",
    "    def compute_metrics(eval_pred):\n",
    "        precision_metric = load_metric(\"precision\")\n",
    "        recall_metric = load_metric(\"recall\")\n",
    "        f1_metric = load_metric(\"f1\")\n",
    "        accuracy_metric = load_metric(\"accuracy\")\n",
    "\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        precision = precision_metric.compute(predictions=predictions, references=labels,average='macro')[\"precision\"]\n",
    "        recall = recall_metric.compute(predictions=predictions, references=labels,average='macro')[\"recall\"]\n",
    "        f1 = f1_metric.compute(predictions=predictions, references=labels,average='macro')['f1']\n",
    "        accuracy = accuracy_metric.compute(predictions=predictions, references=labels)['accuracy']\n",
    "        return {\"precision\": precision, \"recall\": recall, \"f1\":f1, \"accuracy\":accuracy}\n",
    "\n",
    "    \n",
    "    # def compute_metrics(eval_pred):\n",
    "    #     predictions, labels = eval_pred\n",
    "    #     id2label = model.config.id2label\n",
    "    #     predictions = np.argmax(predictions, axis=1)\n",
    "    #     # report = classification_report(labels,\n",
    "    #     #               predictions, output_dict=True,zero_division=0)\n",
    "    #     # per_label = {} \n",
    "    #     # for k,v in report.items():\n",
    "    #     #     if k.isdigit():\n",
    "    #     #         label = id2label[int(k)]\n",
    "    #     #         metrics = v['f1-score']\n",
    "    #     #         per_label[f\"{label}_f1\"] = metrics  \n",
    "    #     return f1.compute(predictions=predictions, references=labels, average='macro')\n",
    "\n",
    "\n",
    "    trainer = Trainer(model,\n",
    "                      args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=feature_extractor)\n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = train_model(data, \"facebook/deit-tiny-patch16-224\",0.001, fp16=False, hub_model_id='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trainer.predict(data.test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_confusion_matrix(outputs, trainer):\n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    y_true = outputs.label_ids\n",
    "    y_pred = outputs.predictions.argmax(1)\n",
    "    labels =trainer.model.config.id2label.values()\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(xticks_rotation=45, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(outputs,trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_classification_report(outputs, trainer):\n",
    "    from sklearn.metrics import classification_report\n",
    "    y_true = outputs.label_ids\n",
    "    y_pred = outputs.predictions.argmax(1)\n",
    "    labels =trainer.model.config.id2label.values()\n",
    "    return classification_report(y_true, y_pred, target_names=labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = create_classification_report(outputs, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kwargs = {\n",
    "#         \"tasks\": \"image-classification\",\n",
    "#         \"tags\": [\"image-classification\", \"vision\"],\n",
    "#     }\n",
    "   \n",
    "# #trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misclasified report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_ds[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_test_results_df(outputs, trainer, important_label=None, print_results=True, return_df=False) -> pd.DataFrame:\n",
    "    id2label = trainer.model.config.id2label\n",
    "    y_true = outputs.label_ids\n",
    "    y_pred = outputs.predictions.argmax(1)\n",
    "    y_prob = softmax(outputs.predictions, axis=1)\n",
    "   # ids = test_data['id']\n",
    "    df = pd.DataFrame({\"y_true\":y_true,\"y_pred\": y_pred, \"y_prob\": y_prob.max(1)})\n",
    "    df.y_true = df.y_true.map(id2label)\n",
    "    df.y_pred = df.y_pred.map(id2label)\n",
    "    if print_results:\n",
    "        misclassified_df = df[df.y_true != df.y_pred]\n",
    "        print('misclasified:')\n",
    "        print(misclassified_df)\n",
    "        print('\\n')\n",
    "        if important_label:\n",
    "            print(f\"Number of wrong predictions of {important_label} label: {len(misclassified_df[misclassified_df['y_pred']==important_label])}\")\n",
    "            print(f\"Percentage of wrong predictions of {important_label} label: {(len(misclassified_df[misclassified_df['y_pred']==important_label])/len(df))*100}\")\n",
    "    if return_df:\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_test_results_df(outputs, trainer, print_results=True,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# @pn.depends(index_selection)\n",
    "# def get_image(selection):\n",
    "#     id2label = trainer.config.id2label\n",
    "#     image = flyswot_data.test_ds[selection]['image']\n",
    "#     image = pn.Pane(image)\n",
    "#     row = flyswot_data.test_ds[selection]\n",
    "#     string_label = id2label[row['label']]\n",
    "#    # label =  pn.pane.Markdown(f\"\"\"actual label: **{string_label}**\"\"\")\n",
    "#     df_row = df.iloc[selection]\n",
    "#     r = pn.Row(image, pn.Pane(df_row))\n",
    "#     return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_mistakes_image_navigator(test_results_df, flyswot_data,trainer):\n",
    "    import panel as pn\n",
    "    pn.extension()\n",
    "    df = test_results_df\n",
    "    mistakes = df.y_true!=df.y_pred\n",
    "    mistake_ids = df.index[mistakes].tolist()\n",
    "    df = df[mistakes]\n",
    "    df = df.reset_index(drop=True)\n",
    "    subset = flyswot_data.test_ds.select(mistake_ids)\n",
    "    assert len(df) == len(subset)\n",
    "    if len(df)<1:\n",
    "        print(df)\n",
    "        return subset['image'][0]\n",
    "    index_selection = pn.widgets.DiscreteSlider(options=df.index.to_list())\n",
    "    id2label = trainer.model.config.id2label\n",
    "    @pn.depends(index_selection)\n",
    "    def get_image(selection):\n",
    "        image = subset[selection]['image']\n",
    "        image = pn.Pane(image)\n",
    "        #row = flyswot_data.test_ds[selection]\n",
    "       # string_label = id2label[row['label']]\n",
    "       # label =  pn.pane.Markdown(f\"\"\"actual label: **{string_label}**\"\"\")\n",
    "        df_row = df.iloc[selection]\n",
    "        r = pn.Row(image, pn.Pane(df_row))\n",
    "        return r\n",
    "    df = df.reset_index(drop=True)\n",
    "    return pn.Column(index_selection,get_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explorer = create_mistakes_image_navigator(df, data,trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_selection = pn.widgets.DiscreteSlider(options=df.index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_misclassified_report(outputs, trainer, test_data, important_label=None, print_results=True, return_df=False):\n",
    "    id2label = trainer.model.config.id2label\n",
    "    y_true = outputs.label_ids\n",
    "    y_pred = outputs.predictions.argmax(1)\n",
    "    y_prob = softmax(outputs.predictions, axis=1)\n",
    "    df = pd.DataFrame({\"y_true\":y_true,\"y_pred\": y_pred, \"y_prob\": y_prob.max(1)})\n",
    "    df.y_true = df.y_true.map(id2label)\n",
    "    df.y_pred = df.y_pred.map(id2label)\n",
    "    if print_results:\n",
    "        misclassified_df = df[df.y_true != df.y_pred]\n",
    "        print('misclasified:')\n",
    "        print(misclassified_df)\n",
    "        print('\\n')\n",
    "        if important_label:\n",
    "            print(f\"Number of wrong predictions of {important_label} label: {len(misclassified_df[misclassified_df['y_pred']==important_label])}\")\n",
    "            print(f\"Percentage of wrong predictions of {important_label} label: {(len(misclassified_df[misclassified_df['y_pred']==important_label])/len(df))*100}\")\n",
    "    if return_df:\n",
    "        return misclassified_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(df, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.y_prob.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['y_pred']=='FLYSHEET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['y_pred']=='FLYSHEET'].sort_values('y_prob',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = outputs.label_ids\n",
    "# y_pred = outputs.predictions.argmax(1)\n",
    "# df = pd.DataFrame({\"y_true\":y_true,\"y_pred\": y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tidy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "shutil.rmtree(\"output_dir\")\n",
    "shutil.rmtree(\"flyswot-gym-testing\")\n",
    "shutil.rmtree(\"testdataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
