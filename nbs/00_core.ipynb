{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core functionality\n",
    "\n",
    "> Core functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import transformers\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from dataclasses import asdict\n",
    "from collections import OrderedDict\n",
    "from typing import Union, Tuple, Sequence, Set\n",
    "from numpy.random import RandomState\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torchvision.transforms import (\n",
    "                                    RandomErasing,\n",
    "                                    RandomAutocontrast,\n",
    "                                    Compose, \n",
    "                                    Normalize, \n",
    "                                    RandomHorizontalFlip,\n",
    "                                    RandomResizedCrop, \n",
    "                                    Resize, \n",
    "                                    RandomAdjustSharpness,\n",
    "                                    ToTensor)\n",
    "import torch\n",
    "from transformers import AutoFeatureExtractor, TrainingArguments, Trainer\n",
    "from transformers import AutoModelForImageClassification\n",
    "from evaluate import load as load_metric\n",
    "from rich import print\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "from tqdm.auto import tqdm\n",
    "from imagededup.methods import PHash\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Git hooks.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git lfs update --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "from toolz.dicttoolz import valmap\n",
    "from collections import Counter\n",
    "from toolz import frequencies\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://huggingface.co/datasets/davanstrien/testgitupload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset = Path(\"testdataset\")\n",
    "testdataset.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = {\"control\": Image.open(\"testdata/add_ms_05422_fcontrol1.jpg\"),\n",
    "\"flysheet\": Image.open(\"testdata/add_ms_9403_fse001v.jpg\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in {\"control\",\"flysheet\"}:\n",
    "    folder = testdataset/label\n",
    "    folder.mkdir()\n",
    "    image = test_images[label]\n",
    "    for i in range(100):\n",
    "        fname = f\"{i}_{label}\"\n",
    "        image.save(f\"{folder}/{fname}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "phasher = PHash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 10:47:53,861: INFO Start: Calculating hashes...\n",
      "0it [00:00, ?it/s]\n",
      "2022-12-12 10:47:53,970: INFO End: Calculating hashes!\n"
     ]
    }
   ],
   "source": [
    "encodings = phasher.encode_images(image_dir='testdataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 10:47:53,988: INFO Start: Calculating hashes...\n",
      "0it [00:00, ?it/s]\n",
      "2022-12-12 10:47:54,068: INFO End: Calculating hashes!\n",
      "2022-12-12 10:47:54,069: INFO Start: Evaluating hamming distances for getting duplicates\n",
      "2022-12-12 10:47:54,071: INFO Start: Retrieving duplicates using Cython Brute force algorithm\n",
      "0it [00:00, ?it/s]\n",
      "2022-12-12 10:47:54,157: INFO End: Retrieving duplicates using Cython Brute force algorithm\n",
      "2022-12-12 10:47:54,159: INFO End: Evaluating hamming distances for getting duplicates\n"
     ]
    }
   ],
   "source": [
    "duplicates = phasher.find_duplicates(image_dir=\"testdataset\", encoding_map=encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Resolving data files:   0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ffabbde6e4a4ac795c6aa5c0c805585"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2cddcb8c7d26937e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /Users/dvanstrien/.cache/huggingface/datasets/imagefolder/default-2cddcb8c7d26937e/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n",
      "                "
     ]
    },
    {
     "data": {
      "text/plain": "Downloading data files #2:   0%|          | 0/13 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c7a8829ef0b465ebe93f668ad9ec425"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #3:   0%|          | 0/13 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74f56e8af7e242ce935489374838c538"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #4:   0%|          | 0/13 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc36e3e5ffaf41998e626d772294dfb1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #5:   0%|          | 0/13 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73f77538f21a4a13a6d2562598588baa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #0:   0%|          | 0/13 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef36eeaab2224b80b091f2b990337012"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #1:   0%|          | 0/13 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ec14a69ccda471e815b06e791751054"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #15:   0%|          | 0/12 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bdd86dbaa974006831b28c8fa68bfac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #10:   0%|          | 0/12 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "517a51378def4337b88062ad2195d181"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #6:   0%|          | 0/13 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4855a9f068fd4064ba946cda2c9167ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #14:   0%|          | 0/12 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3a1a18deac24af7aaec18629c29976b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #9:   0%|          | 0/12 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d41faa2fa4ec42d6af5084118ad755bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #13:   0%|          | 0/12 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8deb0caa23b4d9fb042be475b92e3b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #7:   0%|          | 0/13 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a3c72d2b95d410aa625d817170181ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #11:   0%|          | 0/12 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00a5891a7db14e73b3965521cc03294c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #12:   0%|          | 0/12 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95edde7bbbb44ff3bce87ba841d3e574"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files #8:   0%|          | 0/12 [00:00<?, ?obj/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b8025d5bc074be5ab4f89646d02dd69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data files: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "360173644ae54b6f8e08f295637db5b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extracting data files: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18a9726842e543a7976a75edcf7d12d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "269c10450eca448485d94488ab4fe352"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /Users/dvanstrien/.cache/huggingface/datasets/imagefolder/default-2cddcb8c7d26937e/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"imagefolder\",data_dir=\"testdataset\",\n",
    "                  streaming=False,\n",
    "                  split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['image', 'label'],\n    num_rows: 200\n})"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'/Users/dvanstrien/Documents/DS/gym/nbs/testdataset/control/0_control.jpg'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['image'].filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def filter_bad_images(ds: Dataset):\n",
    "    idx = list(range(len(ds)))\n",
    "    for i in tqdm(idx):\n",
    "        try:\n",
    "            if isinstance(ds[i]['image'], Image.Image):\n",
    "                continue\n",
    "            else:\n",
    "                idx.pop(i)\n",
    "        except OSError:\n",
    "            idx.pop(i)\n",
    "    return ds.select(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c749a967806440488b8232fa5256996"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = filter_bad_images(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['image', 'label'],\n    num_rows: 200\n})"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_fpath(ds: Dataset):\n",
    "   return ds.map(lambda x: {'fpath': x['image'].filename})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a1ed6da0d694cb588a41d227ce61715"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = get_fpath(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=687x1000>,\n 'label': 0,\n 'fpath': '/Users/dvanstrien/Documents/DS/gym/nbs/testdataset/control/0_control.jpg'}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =  '/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r (1).jpg.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r (1).jpg.jpg'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = re.sub(r\"(\\(\\d\\))\",\"\",f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r/Users/dvanstrien/Documents/DS/hmd_flysheet_detection/data/Flysheet_data/CONTAINER/or_5268_fse002r '"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def return_base_path_deduplicated(x):\n",
    "    f = x['fpath']\n",
    "    f = re.sub(r\"(\\(\\d\\))\",\"\",f)\n",
    "    f = f.split(\".\")[0]\n",
    "    f = f.rstrip()\n",
    "    return {\"clean_path\": re.sub(r\"(\\(\\d\\))\",\"\",f)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_uniques(example, uniques, column='clean_path'):\n",
    "    if example[column] in uniques:\n",
    "        uniques.remove(example[column])\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def drop_duplicates(ds):\n",
    "    ds = ds.map(return_base_path_deduplicated)\n",
    "    uniques = set(ds['clean_path'])\n",
    "    ds = ds.filter(check_uniques, fn_kwargs={\"uniques\":uniques})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc6dbac24f494639aab453902bd56b9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "522f053a46f34ab4bceac814ab9a417c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = drop_duplicates(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['image', 'label', 'fpath', 'clean_path'],\n    num_rows: 200\n})"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_id(example):\n",
    "    x = example[\"fpath\"]\n",
    "    x = Path(x).name.split(\"_\")\n",
    "    return {\"id\": \"_\".join(x[:2] if len(x) >= 3 else x[:3])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, valid, test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_w_stratify(\n",
    "    ds,\n",
    "    test_size: Union[int, float],\n",
    "    random_state: Union[int, RandomState, None] = None,\n",
    ") -> Tuple[Dataset, Dataset]:\n",
    "    labels = ds['label']\n",
    "    label_array = np.array(labels)\n",
    "    train_inds, valid_inds = next(\n",
    "        StratifiedShuffleSplit(\n",
    "            n_splits=3, test_size=test_size, random_state=random_state\n",
    "        ).split(np.zeros(len(labels)), y=label_array)\n",
    "    )\n",
    "    return ds.select(train_inds), ds.select(valid_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = split_w_stratify(ds, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_allclose(train.shape, valid.shape,rtol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{1: 50, 0: 50}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_freqs = frequencies(train['label'])\n",
    "train_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "odict_values([25.0, 25.0])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_percentages =  OrderedDict(sorted(valmap(lambda x: x/len(train_freqs),train_freqs).items())).values()\n",
    "train_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "odict_values([25.0, 25.0])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_freqs = frequencies(valid['label'])\n",
    "valid_percentages = OrderedDict(sorted(valmap(lambda x: x/len(valid_freqs),valid_freqs).items())).values()\n",
    "valid_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_allclose(list(train_percentages), list(valid_percentages), atol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_valid_split_w_stratify(\n",
    "    ds,\n",
    "    valid_size: Union[int,float]=None,\n",
    "    test_size: Union[int, float]=0.2,\n",
    "    train_size: Union[int, float, None] = None,\n",
    "    random_state: Union[int, RandomState, None] = None,\n",
    ") -> Tuple[Dataset,Dataset, Dataset]:\n",
    "    train, valid_test = split_w_stratify(ds, test_size=test_size)\n",
    "    valid, test = split_w_stratify(valid_test, test_size=0.1)\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = train_valid_split_w_stratify(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prepare_dataset(ds):\n",
    "    print(\"Preparing dataset...\")\n",
    "    print(\"dropping duplicates...\")\n",
    "    ds = filter_bad_images(ds)\n",
    "    # ds = get_fpath(ds)\n",
    "    # ds = drop_duplicates(ds)\n",
    "    # print(\"getting ID...\")\n",
    "    # ds = ds.map(get_id)\n",
    "    print(\"creating train, valid, test splits...\")\n",
    "    train, valid, test = train_valid_split_w_stratify(ds)\n",
    "    data = {\"train\": train,\n",
    "            \"valid\": valid,\n",
    "            \"test\": test}\n",
    "    for k,v  in data.items():\n",
    "        print(f\"{k} has {len(v)} examples\")\n",
    "    return train,valid,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Resolving data files:   0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a44ab06bf3bb40ec8707d248ddeb37c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2cddcb8c7d26937e\n",
      "Found cached dataset imagefolder (/Users/dvanstrien/.cache/huggingface/datasets/imagefolder/default-2cddcb8c7d26937e/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"imagefolder\",data_dir=\"testdataset\",\n",
    "                  split='train',use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Preparing dataset\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "dropping duplicates\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">dropping duplicates<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f6f60d8a2d34ce1814a95a4cff1bbd2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "creating train, valid, test splits\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">creating train, valid, test splits<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "train has \u001B[1;36m160\u001B[0m examples\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">train has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span> examples\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "valid has \u001B[1;36m36\u001B[0m examples\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">valid has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> examples\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "test has \u001B[1;36m4\u001B[0m examples\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> examples\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(Dataset({\n     features: ['image', 'label'],\n     num_rows: 160\n }),\n Dataset({\n     features: ['image', 'label'],\n     num_rows: 36\n }),\n Dataset({\n     features: ['image', 'label'],\n     num_rows: 4\n }))"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,valid,test = prepare_dataset(ds)\n",
    "train,valid,test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"davanstrien/vit-base-patch16-224-in21k-base-manuscripts\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prepare_transforms(model_checkpoint, train_ds, valid_ds, test_ds=None):\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)\n",
    "    normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "    _train_transforms = Compose(\n",
    "            [\n",
    "                Resize((feature_extractor.size['height'],feature_extractor.size['width'])),\n",
    "                RandomAdjustSharpness(0.1),\n",
    "                RandomAutocontrast(),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "                RandomErasing()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    _val_transforms = Compose(\n",
    "            [\n",
    "                Resize((feature_extractor.size['height'],feature_extractor.size['width'])),\n",
    "                ToTensor(),\n",
    "                normalize,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def train_transforms(examples):\n",
    "        examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "        return examples\n",
    "\n",
    "    def val_transforms(examples):\n",
    "        examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "        return examples\n",
    "    if test_ds is not None:\n",
    "        test_ds.set_transform(val_transforms)\n",
    "    train_ds.set_transform(train_transforms)\n",
    "    valid_ds.set_transform(val_transforms)\n",
    "    return train_ds, valid_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds, test_ds = prepare_transforms(model_checkpoint, train,valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class FlyswotData:\n",
    "    train_ds: datasets.arrow_dataset.Dataset\n",
    "    valid_ds: datasets.arrow_dataset.Dataset\n",
    "    test_ds: datasets.arrow_dataset.Dataset\n",
    "    id2label: Dict[int,str]\n",
    "    label2id: Dict[str,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prep_data(ds, model_checkpoint=None):\n",
    "    try:\n",
    "        labels = ds.features['label'].names\n",
    "        id2label = dict(enumerate(labels))\n",
    "        label2id = {v:k for k,v in id2label.items()}\n",
    "        train, valid, test = prepare_dataset(ds)\n",
    "        train_ds, valid_ds, test_ds = prepare_transforms(model_checkpoint, train, valid, test)\n",
    "        return FlyswotData(train_ds, valid_ds, test_ds, id2label, label2id)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"{e} make sure you are logged into the Hugging Face Hub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Preparing dataset\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "dropping duplicates\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">dropping duplicates<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/994 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4acbe3628bce47acbc8b8251cf58b17a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "creating train, valid, test splits\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">creating train, valid, test splits<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "train has \u001B[1;36m795\u001B[0m examples\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">train has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">795</span> examples\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "valid has \u001B[1;36m179\u001B[0m examples\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">valid has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">179</span> examples\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "test has \u001B[1;36m20\u001B[0m examples\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">test has <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "FlyswotData(train_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 795\n}), valid_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 179\n}), test_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 20\n}), id2label={0: 'CONTAINER', 1: 'CONTROL%20SHOT', 2: 'COVER', 3: 'EDGE%20%2B%20SPINE', 4: 'FLYSHEET', 5: 'OTHER', 6: 'PAGE%20%2B%20FOLIO', 7: 'SCROLL'}, label2id={'CONTAINER': 0, 'CONTROL%20SHOT': 1, 'COVER': 2, 'EDGE%20%2B%20SPINE': 3, 'FLYSHEET': 4, 'OTHER': 5, 'PAGE%20%2B%20FOLIO': 6, 'SCROLL': 7})"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prep_data(ds, model_checkpoint=model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "FlyswotData(train_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 795\n}), valid_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 179\n}), test_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 20\n}), id2label={0: 'CONTAINER', 1: 'CONTROL%20SHOT', 2: 'COVER', 3: 'EDGE%20%2B%20SPINE', 4: 'FLYSHEET', 5: 'OTHER', 6: 'PAGE%20%2B%20FOLIO', 7: 'SCROLL'}, label2id={'CONTAINER': 0, 'CONTROL%20SHOT': 1, 'COVER': 2, 'EDGE%20%2B%20SPINE': 3, 'FLYSHEET': 4, 'OTHER': 5, 'PAGE%20%2B%20FOLIO': 6, 'SCROLL': 7})"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds, test_ds, id2label, label2id = asdict(data).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['image', 'label'],\n    num_rows: 795\n})"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_model(data, \n",
    "                model_checkpoint,\n",
    "                num_epochs=50,\n",
    "                hub_model_id=\"flyswot\",\n",
    "                tune=False,\n",
    "               fp16=True):\n",
    "    transformers.logging.set_verbosity_warning()\n",
    "    train_ds, valid_ds, test_ds, id2label, label2id = asdict(data).values()\n",
    "    print(train_ds)\n",
    "    model = AutoModelForImageClassification.from_pretrained(model_checkpoint, num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                  label2id=label2id, ignore_mismatched_sizes=True)\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)\n",
    "    args = TrainingArguments(\n",
    "    \"output_dir\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    hub_model_id=f\"flyswot/{hub_model_id}\",\n",
    "    overwrite_output_dir=True,\n",
    "    push_to_hub=False,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4, \n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.1,disable_tqdm=False,\n",
    "    fp16=fp16,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_dir='logs',\n",
    "    remove_unused_columns=False,\n",
    "    save_total_limit=10,\n",
    "    optim=\"adamw_torch\",\n",
    "    seed=42,    \n",
    ")\n",
    "    def compute_metrics(eval_pred):\n",
    "        precision_metric = load_metric(\"precision\")\n",
    "        recall_metric = load_metric(\"recall\")\n",
    "        f1_metric = load_metric(\"f1\")\n",
    "        accuracy_metric = load_metric(\"accuracy\")\n",
    "\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        precision = precision_metric.compute(predictions=predictions, references=labels,average='macro')[\"precision\"]\n",
    "        recall = recall_metric.compute(predictions=predictions, references=labels,average='macro')[\"recall\"]\n",
    "        f1 = f1_metric.compute(predictions=predictions, references=labels,average='macro')['f1']\n",
    "        accuracy = accuracy_metric.compute(predictions=predictions, references=labels)['accuracy']\n",
    "        return {\"precision\": precision, \"recall\": recall, \"f1\":f1, \"accuracy\":accuracy}\n",
    "\n",
    "    trainer = Trainer(model,\n",
    "                      args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=feature_extractor)\n",
    "    trainer.train()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1;35mDataset\u001B[0m\u001B[1m(\u001B[0m\u001B[1m{\u001B[0m\n    features: \u001B[1m[\u001B[0m\u001B[32m'image'\u001B[0m, \u001B[32m'label'\u001B[0m\u001B[1m]\u001B[0m,\n    num_rows: \u001B[1;36m795\u001B[0m\n\u001B[1m}\u001B[0m\u001B[1m)\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n    features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'image'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'label'</span><span style=\"font-weight: bold\">]</span>,\n    num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">795</span>\n<span style=\"font-weight: bold\">})</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 192]) in the checkpoint and torch.Size([8, 192]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([8]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 795\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "  Number of trainable parameters = 5525960\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/1 : < :, Epoch 0.01/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 179\n",
      "  Batch size = 4\n",
      "/Users/dvanstrien/Documents/DS/gym/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to output_dir/checkpoint-1\n",
      "Configuration saved in output_dir/checkpoint-1/config.json\n",
      "Model weights saved in output_dir/checkpoint-1/pytorch_model.bin\n",
      "Image processor saved in output_dir/checkpoint-1/preprocessor_config.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from output_dir/checkpoint-1 (score: 0.20914715701875866).\n"
     ]
    }
   ],
   "source": [
    "trainer = train_model(data, \"facebook/deit-tiny-patch16-224\",0.001, fp16=False, hub_model_id='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "FlyswotData(train_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 795\n}), valid_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 179\n}), test_ds=Dataset({\n    features: ['image', 'label'],\n    num_rows: 20\n}), id2label={0: 'CONTAINER', 1: 'CONTROL%20SHOT', 2: 'COVER', 3: 'EDGE%20%2B%20SPINE', 4: 'FLYSHEET', 5: 'OTHER', 6: 'PAGE%20%2B%20FOLIO', 7: 'SCROLL'}, label2id={'CONTAINER': 0, 'CONTROL%20SHOT': 1, 'COVER': 2, 'EDGE%20%2B%20SPINE': 3, 'FLYSHEET': 4, 'OTHER': 5, 'PAGE%20%2B%20FOLIO': 6, 'SCROLL': 7})"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/5 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dvanstrien/Documents/DS/gym/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "outputs = trainer.predict(data.test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'test_loss': 1.9036948680877686,\n 'test_precision': 0.20238095238095236,\n 'test_recall': 0.16666666666666666,\n 'test_f1': 0.18095238095238095,\n 'test_accuracy': 0.3,\n 'test_runtime': 12.3261,\n 'test_samples_per_second': 1.623,\n 'test_steps_per_second': 0.406}"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_confusion_matrix(outputs, trainer):\n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    y_true = outputs.label_ids\n",
    "    y_pred = outputs.predictions.argmax(1)\n",
    "    labels =trainer.model.config.id2label.values()\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(xticks_rotation=45, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (7), usually from a call to set_ticks, does not match the number of ticklabels (8).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[73], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mplot_confusion_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[72], line 11\u001B[0m, in \u001B[0;36mplot_confusion_matrix\u001B[0;34m(outputs, trainer)\u001B[0m\n\u001B[1;32m      9\u001B[0m cm \u001B[38;5;241m=\u001B[39m confusion_matrix(y_true, y_pred)\n\u001B[1;32m     10\u001B[0m disp \u001B[38;5;241m=\u001B[39m ConfusionMatrixDisplay(confusion_matrix\u001B[38;5;241m=\u001B[39mcm, display_labels\u001B[38;5;241m=\u001B[39mlabels)\n\u001B[0;32m---> 11\u001B[0m \u001B[43mdisp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxticks_rotation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m45\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43max\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/DS/gym/venv/lib/python3.10/site-packages/sklearn/metrics/_plot/confusion_matrix.py:172\u001B[0m, in \u001B[0;36mConfusionMatrixDisplay.plot\u001B[0;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw)\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m colorbar:\n\u001B[1;32m    171\u001B[0m     fig\u001B[38;5;241m.\u001B[39mcolorbar(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mim_, ax\u001B[38;5;241m=\u001B[39max)\n\u001B[0;32m--> 172\u001B[0m \u001B[43max\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxticks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marange\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_classes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43myticks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marange\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_classes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxticklabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisplay_labels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[43myticklabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisplay_labels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m    \u001B[49m\u001B[43mylabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTrue label\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPredicted label\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    181\u001B[0m ax\u001B[38;5;241m.\u001B[39mset_ylim((n_classes \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m0.5\u001B[39m))\n\u001B[1;32m    182\u001B[0m plt\u001B[38;5;241m.\u001B[39msetp(ax\u001B[38;5;241m.\u001B[39mget_xticklabels(), rotation\u001B[38;5;241m=\u001B[39mxticks_rotation)\n",
      "File \u001B[0;32m~/Documents/DS/gym/venv/lib/python3.10/site-packages/matplotlib/artist.py:117\u001B[0m, in \u001B[0;36mArtist.__init_subclass__.<locals>.<lambda>\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mset, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_autogenerated_signature\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    110\u001B[0m     \u001B[38;5;66;03m# Don't overwrite cls.set if the subclass or one of its parents\u001B[39;00m\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;66;03m# has defined a set method set itself.\u001B[39;00m\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;66;03m# If there was no explicit definition, cls.set is inherited from\u001B[39;00m\n\u001B[1;32m    113\u001B[0m     \u001B[38;5;66;03m# the hierarchy of auto-generated set methods, which hold the\u001B[39;00m\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;66;03m# flag _autogenerated_signature.\u001B[39;00m\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m--> 117\u001B[0m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m \u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: \u001B[43mArtist\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mset\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mset\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mset\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.set\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/Documents/DS/gym/venv/lib/python3.10/site-packages/matplotlib/artist.py:1194\u001B[0m, in \u001B[0;36mArtist.set\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1191\u001B[0m     \u001B[38;5;66;03m# docstring and signature are auto-generated via\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m     \u001B[38;5;66;03m# Artist._update_set_signature_and_docstring() at the end of the\u001B[39;00m\n\u001B[1;32m   1193\u001B[0m     \u001B[38;5;66;03m# module.\u001B[39;00m\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_internal_update\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcbook\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalize_kwargs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/DS/gym/venv/lib/python3.10/site-packages/matplotlib/artist.py:1186\u001B[0m, in \u001B[0;36mArtist._internal_update\u001B[0;34m(self, kwargs)\u001B[0m\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_internal_update\u001B[39m(\u001B[38;5;28mself\u001B[39m, kwargs):\n\u001B[1;32m   1180\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1181\u001B[0m \u001B[38;5;124;03m    Update artist properties without prenormalizing them, but generating\u001B[39;00m\n\u001B[1;32m   1182\u001B[0m \u001B[38;5;124;03m    errors as if calling `set`.\u001B[39;00m\n\u001B[1;32m   1183\u001B[0m \n\u001B[1;32m   1184\u001B[0m \u001B[38;5;124;03m    The lack of prenormalization is to maintain backcompatibility.\u001B[39;00m\n\u001B[1;32m   1185\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_props\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1187\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{cls.__name__}\u001B[39;49;00m\u001B[38;5;124;43m.set() got an unexpected keyword argument \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m   1188\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{prop_name!r}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/DS/gym/venv/lib/python3.10/site-packages/matplotlib/artist.py:1162\u001B[0m, in \u001B[0;36mArtist._update_props\u001B[0;34m(self, props, errfmt)\u001B[0m\n\u001B[1;32m   1159\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m callable(func):\n\u001B[1;32m   1160\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[1;32m   1161\u001B[0m                     errfmt\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m), prop_name\u001B[38;5;241m=\u001B[39mk))\n\u001B[0;32m-> 1162\u001B[0m             ret\u001B[38;5;241m.\u001B[39mappend(\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1163\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret:\n\u001B[1;32m   1164\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpchanged()\n",
      "File \u001B[0;32m~/Documents/DS/gym/venv/lib/python3.10/site-packages/matplotlib/axes/_base.py:73\u001B[0m, in \u001B[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/DS/gym/venv/lib/python3.10/site-packages/matplotlib/axis.py:1968\u001B[0m, in \u001B[0;36mAxis._set_ticklabels\u001B[0;34m(self, labels, fontdict, minor, **kwargs)\u001B[0m\n\u001B[1;32m   1966\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fontdict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1967\u001B[0m     kwargs\u001B[38;5;241m.\u001B[39mupdate(fontdict)\n\u001B[0;32m-> 1968\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_ticklabels\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mminor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mminor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/DS/gym/venv/lib/python3.10/site-packages/matplotlib/axis.py:1890\u001B[0m, in \u001B[0;36mAxis.set_ticklabels\u001B[0;34m(self, ticklabels, minor, **kwargs)\u001B[0m\n\u001B[1;32m   1886\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(locator, mticker\u001B[38;5;241m.\u001B[39mFixedLocator):\n\u001B[1;32m   1887\u001B[0m     \u001B[38;5;66;03m# Passing [] as a list of ticklabels is often used as a way to\u001B[39;00m\n\u001B[1;32m   1888\u001B[0m     \u001B[38;5;66;03m# remove all tick labels, so only error for > 0 ticklabels\u001B[39;00m\n\u001B[1;32m   1889\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(locator\u001B[38;5;241m.\u001B[39mlocs) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(ticklabels) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(ticklabels) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1890\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1891\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe number of FixedLocator locations\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1892\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(locator\u001B[38;5;241m.\u001B[39mlocs)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m), usually from a call to\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1893\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m set_ticks, does not match\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1894\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m the number of ticklabels (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(ticklabels)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1895\u001B[0m     tickd \u001B[38;5;241m=\u001B[39m {loc: lab \u001B[38;5;28;01mfor\u001B[39;00m loc, lab \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(locator\u001B[38;5;241m.\u001B[39mlocs, ticklabels)}\n\u001B[1;32m   1896\u001B[0m     func \u001B[38;5;241m=\u001B[39m functools\u001B[38;5;241m.\u001B[39mpartial(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_with_dict, tickd)\n",
      "\u001B[0;31mValueError\u001B[0m: The number of FixedLocator locations (7), usually from a call to set_ticks, does not match the number of ticklabels (8)."
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1500x1500 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(outputs,trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_classification_report(outputs, trainer):\n",
    "    from sklearn.metrics import classification_report\n",
    "    y_true = outputs.label_ids\n",
    "    y_pred = outputs.predictions.argmax(1)\n",
    "    labels =trainer.model.config.id2label.values()\n",
    "    return classification_report(y_true, y_pred, target_names=labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 7, does not match size of target_names, 8. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[75], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_classification_report\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[74], line 7\u001B[0m, in \u001B[0;36mcreate_classification_report\u001B[0;34m(outputs, trainer)\u001B[0m\n\u001B[1;32m      5\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mpredictions\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      6\u001B[0m labels \u001B[38;5;241m=\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mid2label\u001B[38;5;241m.\u001B[39mvalues()\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mclassification_report\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/DS/gym/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2154\u001B[0m, in \u001B[0;36mclassification_report\u001B[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001B[0m\n\u001B[1;32m   2148\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   2149\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels size, \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m, does not match size of target_names, \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   2150\u001B[0m                 \u001B[38;5;28mlen\u001B[39m(labels), \u001B[38;5;28mlen\u001B[39m(target_names)\n\u001B[1;32m   2151\u001B[0m             )\n\u001B[1;32m   2152\u001B[0m         )\n\u001B[1;32m   2153\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2154\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   2155\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of classes, \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m, does not match size of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2156\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget_names, \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m. Try specifying the labels \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2157\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mlen\u001B[39m(labels), \u001B[38;5;28mlen\u001B[39m(target_names))\n\u001B[1;32m   2158\u001B[0m         )\n\u001B[1;32m   2159\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m target_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2160\u001B[0m     target_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m l \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m labels]\n",
      "\u001B[0;31mValueError\u001B[0m: Number of classes, 7, does not match size of target_names, 8. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "results = create_classification_report(outputs, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kwargs = {\n",
    "#         \"tasks\": \"image-classification\",\n",
    "#         \"tags\": [\"image-classification\", \"vision\"],\n",
    "#     }\n",
    "   \n",
    "# #trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misclasified report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_ds[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_test_results_df(outputs, trainer, important_label=None, print_results=True, return_df=False) -> pd.DataFrame:\n",
    "    id2label = trainer.model.config.id2label\n",
    "    y_true = outputs.label_ids\n",
    "    y_pred = outputs.predictions.argmax(1)\n",
    "    y_prob = softmax(outputs.predictions, axis=1)\n",
    "   # ids = test_data['id']\n",
    "    df = pd.DataFrame({\"y_true\":y_true,\"y_pred\": y_pred, \"y_prob\": y_prob.max(1)})\n",
    "    df.y_true = df.y_true.map(id2label)\n",
    "    df.y_pred = df.y_pred.map(id2label)\n",
    "    if print_results:\n",
    "        misclassified_df = df[df.y_true != df.y_pred]\n",
    "        print('misclasified:')\n",
    "        print(misclassified_df)\n",
    "        print('\\n')\n",
    "        if important_label:\n",
    "            print(f\"Number of wrong predictions of {important_label} label: {len(misclassified_df[misclassified_df['y_pred']==important_label])}\")\n",
    "            print(f\"Percentage of wrong predictions of {important_label} label: {(len(misclassified_df[misclassified_df['y_pred']==important_label])/len(df))*100}\")\n",
    "    if return_df:\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_test_results_df(outputs, trainer, print_results=True,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# @pn.depends(index_selection)\n",
    "# def get_image(selection):\n",
    "#     id2label = trainer.config.id2label\n",
    "#     image = flyswot_data.test_ds[selection]['image']\n",
    "#     image = pn.Pane(image)\n",
    "#     row = flyswot_data.test_ds[selection]\n",
    "#     string_label = id2label[row['label']]\n",
    "#    # label =  pn.pane.Markdown(f\"\"\"actual label: **{string_label}**\"\"\")\n",
    "#     df_row = df.iloc[selection]\n",
    "#     r = pn.Row(image, pn.Pane(df_row))\n",
    "#     return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_mistakes_image_navigator(test_results_df, flyswot_data,trainer):\n",
    "    import panel as pn\n",
    "    pn.extension()\n",
    "    df = test_results_df\n",
    "    mistakes = df.y_true!=df.y_pred\n",
    "    mistake_ids = df.index[mistakes].tolist()\n",
    "    df = df[mistakes]\n",
    "    df = df.reset_index(drop=True)\n",
    "    subset = flyswot_data.test_ds.select(mistake_ids)\n",
    "    assert len(df) == len(subset)\n",
    "    if len(df)<1:\n",
    "        print(df)\n",
    "        return subset['image'][0]\n",
    "    index_selection = pn.widgets.DiscreteSlider(options=df.index.to_list())\n",
    "    id2label = trainer.model.config.id2label\n",
    "    @pn.depends(index_selection)\n",
    "    def get_image(selection):\n",
    "        image = subset[selection]['image']\n",
    "        image = pn.Pane(image)\n",
    "        #row = flyswot_data.test_ds[selection]\n",
    "       # string_label = id2label[row['label']]\n",
    "       # label =  pn.pane.Markdown(f\"\"\"actual label: **{string_label}**\"\"\")\n",
    "        df_row = df.iloc[selection]\n",
    "        r = pn.Row(image, pn.Pane(df_row))\n",
    "        return r\n",
    "    df = df.reset_index(drop=True)\n",
    "    return pn.Column(index_selection,get_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explorer = create_mistakes_image_navigator(df, data,trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_selection = pn.widgets.DiscreteSlider(options=df.index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_misclassified_report(outputs, trainer, test_data, important_label=None, print_results=True, return_df=False):\n",
    "    id2label = trainer.model.config.id2label\n",
    "    y_true = outputs.label_ids\n",
    "    y_pred = outputs.predictions.argmax(1)\n",
    "    y_prob = softmax(outputs.predictions, axis=1)\n",
    "    df = pd.DataFrame({\"y_true\":y_true,\"y_pred\": y_pred, \"y_prob\": y_prob.max(1)})\n",
    "    df.y_true = df.y_true.map(id2label)\n",
    "    df.y_pred = df.y_pred.map(id2label)\n",
    "    if print_results:\n",
    "        misclassified_df = df[df.y_true != df.y_pred]\n",
    "        print('misclasified:')\n",
    "        print(misclassified_df)\n",
    "        print('\\n')\n",
    "        if important_label:\n",
    "            print(f\"Number of wrong predictions of {important_label} label: {len(misclassified_df[misclassified_df['y_pred']==important_label])}\")\n",
    "            print(f\"Percentage of wrong predictions of {important_label} label: {(len(misclassified_df[misclassified_df['y_pred']==important_label])/len(df))*100}\")\n",
    "    if return_df:\n",
    "        return misclassified_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(df, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.y_prob.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['y_pred']=='FLYSHEET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['y_pred']=='FLYSHEET'].sort_values('y_prob',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = outputs.label_ids\n",
    "# y_pred = outputs.predictions.argmax(1)\n",
    "# df = pd.DataFrame({\"y_true\":y_true,\"y_pred\": y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tidy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "shutil.rmtree(\"output_dir\")\n",
    "shutil.rmtree(\"testdataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
